<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>PitmanYorMixture · BayesDensity.jl</title><meta name="title" content="PitmanYorMixture · BayesDensity.jl"/><meta property="og:title" content="PitmanYorMixture · BayesDensity.jl"/><meta property="twitter:title" content="PitmanYorMixture · BayesDensity.jl"/><meta name="description" content="Documentation for BayesDensity.jl."/><meta property="og:description" content="Documentation for BayesDensity.jl."/><meta property="twitter:description" content="Documentation for BayesDensity.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="BayesDensity.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">BayesDensity.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../density_estimation_primer/">A primer on Bayesian nonparametric density estimation</a></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../../api/general_api/">General API</a></li><li><a class="tocitem" href="../../api/plotting_api/">Plotting API</a></li></ul></li><li><span class="tocitem">Methods</span><ul><li><a class="tocitem" href="../">Index</a></li><li><a class="tocitem" href="../BSplineMixture/">BSplineMixture</a></li><li><a class="tocitem" href="../HistSmoother/">HistSmoother</a></li><li class="is-active"><a class="tocitem" href>PitmanYorMixture</a><ul class="internal"><li><a class="tocitem" href="#Module-API"><span>Module API</span></a></li></ul></li><li><a class="tocitem" href="../FiniteGaussianMixture/">FiniteGaussianMixture</a></li><li><a class="tocitem" href="../RandomFiniteGaussianMixture/">RandomFiniteGaussianMixture</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/add_new_models/">Implementing new Bayesian density estimators</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Methods</a></li><li class="is-active"><a href>PitmanYorMixture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>PitmanYorMixture</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/oskarhs/BayesDensity.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/oskarhs/BayesDensity.jl/blob/main/docs/src/methods/PitmanYorMixture.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="PitmanYorMixture"><a class="docs-heading-anchor" href="#PitmanYorMixture">PitmanYorMixture</a><a id="PitmanYorMixture-1"></a><a class="docs-heading-anchor-permalink" href="#PitmanYorMixture" title="Permalink"></a></h1><p>Documentation for Pitman-Yor mixture models <a href="../../references/#Ishwaran2001Gibbs">Ishwaran and James (2001)</a>, with a normal kernel and a normal-inverse gamma base measure.</p><p>For Markov chain Monte Carlo based inference, this module implements algorithm 2 by <a href="../../references/#Neal2000Markov">Neal (2000)</a>. For variational inference, we implement the truncated stickbreaking approach of <a href="../../references/#Blei2006DirichletVariational">Blei and Jordan (2006)</a>.</p><div class="admonition is-info" id="Note-fb8897ce31954d59"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-fb8897ce31954d59" title="Permalink"></a></header><div class="admonition-body"><p>Since Dirichlet process mixture models are equivalent to a Pitman-Yor mixture model with discount parameter equal to <code>0</code>, this module can also be used to fit the former type of models.</p></div></div><h2 id="Module-API"><a class="docs-heading-anchor" href="#Module-API">Module API</a><a id="Module-API-1"></a><a class="docs-heading-anchor-permalink" href="#Module-API" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="BayesDensityPitmanYorMixture.PitmanYorMixture"><a class="docstring-binding" href="#BayesDensityPitmanYorMixture.PitmanYorMixture"><code>BayesDensityPitmanYorMixture.PitmanYorMixture</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">PitmanYorMixture{T&lt;:Real} &lt;: AbstractBayesDensityModel{T}</code></pre><p>Struct representing a Pitman-Yor mixture model with a normal kernel and a conjugate Normal-InverseGamma base measure.</p><p><strong>Constructors</strong></p><pre><code class="language-julia hljs">PitmanYorMixture(x::AbstractVector{&lt;:Real}; kwargs...)
PitmanYorMixture{T}(x::AbstractVector{&lt;:Real}; kwargs...)</code></pre><p><strong>Arguments</strong></p><ul><li><code>x</code>: The data vector.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>discount</code>: Discount parameter of the Pitman-Yor process. Defaults to <code>0.0</code>, corresponding to a Dirichlet Process.</li><li><code>strength</code>: Strength parameter of the Pitman-Yor process. Defaults to <code>1.0</code>.</li><li><code>prior_location</code>: Prior mean of the location parameter <code>μ</code>. Defaults to <code>mean(x)</code>.</li><li><code>prior_inv_scale_fac</code>: Factor by which the conditional prior variance <code>σ2</code> of <code>μ</code> is scaled. Defaults to <code>1</code>.</li><li><code>prior_shape</code>: Prior shape parameter of the squared scale parameter <code>σ2</code>: Defaults to <code>2.0</code>.</li><li><code>prior_rate</code>: Prior rate parameter of the squared scale parameter <code>σ2</code>. Defaults to <code>var(x)</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; x = (1.0 .- (1.0 .- LinRange(0.0, 1.0, 5000)) .^(1/3)).^(1/3);

julia&gt; pym = PitmanYorMixture(x)
PitmanYorMixture{Float64}:
Using 5000 observations.
Hyperparameters:
 discount = 0.0, strength = 1.0
 prior_location = 0.578555, prior_inv_scale_fac = 1.0
 prior_shape = 2.0, prior_rate = 0.0334916

julia&gt; pym = PitmanYorMixture(x; strength = 2, discount = 0.5);</code></pre><p><strong>Extended help</strong></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/oskarhs/BayesDensity.jl/blob/60868ddfae2932b3f5aa7ed19c3e21e58d6522de/lib/BayesDensityPitmanYorMixture/src/PitmanYorMixture.jl#L1-L37">source</a></section></details></article><h3 id="Evaluating-the-pdf-and-cdf"><a class="docs-heading-anchor" href="#Evaluating-the-pdf-and-cdf">Evaluating the pdf and cdf</a><a id="Evaluating-the-pdf-and-cdf-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluating-the-pdf-and-cdf" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="Distributions.pdf-Tuple{PitmanYorMixture, NamedTuple, Real}"><a class="docstring-binding" href="#Distributions.pdf-Tuple{PitmanYorMixture, NamedTuple, Real}"><code>Distributions.pdf</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">pdf(
    bsm::PitmanYorMixture,
    params::NamedTuple,
    t::Union{Real, AbstractVector{&lt;:Real}}
) -&gt; Union{Real, Vector{&lt;:Real}}

pdf(
    bsm::PitmanYorMixture,
    params::AbstractVector{NamedTuple},
    t::Union{Real, AbstractVector{&lt;:Real}}
) -&gt; Matrix{&lt;:Real}</code></pre><p>Evaluate <span>$f(t\, |\, \boldsymbol{\eta})$</span> for a given <code>PitmanYorMixture</code> when the model parameters of the NamedTuple <code>params</code> are given by <span>$\boldsymbol{\eta}$</span>.</p><p>The named tuple should contain fields named <code>:μ</code>, <code>:σ2</code> and a third field named <code>:cluster_counts</code> or <code>:w</code>, depending on whether the marginal or stickbreaking parameterization is used.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/oskarhs/BayesDensity.jl/blob/60868ddfae2932b3f5aa7ed19c3e21e58d6522de/lib/BayesDensityPitmanYorMixture/src/PitmanYorMixture.jl#L83-L99">source</a></section></details></article><article><details class="docstring" open="true"><summary id="Distributions.cdf-Tuple{PitmanYorMixture, NamedTuple, Real}"><a class="docstring-binding" href="#Distributions.cdf-Tuple{PitmanYorMixture, NamedTuple, Real}"><code>Distributions.cdf</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">cdf(
    bsm::PitmanYorMixture,
    params::NamedTuple,
    t::Union{Real, AbstractVector{&lt;:Real}}
) -&gt; Union{Real, Vector{&lt;:Real}}

cdf(
    bsm::PitmanYorMixture,
    params::AbstractVector{NamedTuple},
    t::Union{Real, AbstractVector{&lt;:Real}}
) -&gt; Matrix{&lt;:Real}</code></pre><p>Evaluate <span>$F(t\, |\, \boldsymbol{\eta})$</span> for a given <code>PitmanYorMixture</code> when the model parameters of the NamedTuple <code>params</code> are given by <span>$\boldsymbol{\eta}$</span>.</p><p>The named tuple should contain fields named <code>:μ</code>, <code>:σ2</code> and a third field named <code>:cluster_counts</code> or <code>:w</code>, depending on whether the marginal or stickbreaking parameterization is used.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/oskarhs/BayesDensity.jl/blob/60868ddfae2932b3f5aa7ed19c3e21e58d6522de/lib/BayesDensityPitmanYorMixture/src/PitmanYorMixture.jl#L105-L121">source</a></section></details></article><h3 id="Utility-functions"><a class="docs-heading-anchor" href="#Utility-functions">Utility functions</a><a id="Utility-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Utility-functions" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="BayesDensityCore.hyperparams-Tuple{PitmanYorMixture}"><a class="docstring-binding" href="#BayesDensityCore.hyperparams-Tuple{PitmanYorMixture}"><code>BayesDensityCore.hyperparams</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">hyperparams(
    pym::PitmanYorMixture{T}
) where {T} -&gt; @NamedTuple{discount::T, strength::T, prior_location::T, prior_inv_scale_fac::T, prior_shape::T, prior_rate::T}</code></pre><p>Returns the hyperparameters of the Pitman-Yor mixture model <code>pym</code> as a <code>NamedTuple</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/oskarhs/BayesDensity.jl/blob/60868ddfae2932b3f5aa7ed19c3e21e58d6522de/lib/BayesDensityPitmanYorMixture/src/PitmanYorMixture.jl#L59-L65">source</a></section></details></article><h3 id="Markov-chain-Monte-Carlo"><a class="docs-heading-anchor" href="#Markov-chain-Monte-Carlo">Markov chain Monte Carlo</a><a id="Markov-chain-Monte-Carlo-1"></a><a class="docs-heading-anchor-permalink" href="#Markov-chain-Monte-Carlo" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="StatsBase.sample-Tuple{AbstractRNG, PitmanYorMixture, Int64}"><a class="docstring-binding" href="#StatsBase.sample-Tuple{AbstractRNG, PitmanYorMixture, Int64}"><code>StatsBase.sample</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">sample(
    [rng::Random.AbstractRNG],
    pym::PitmanYorMixture{T},
    n_samples::Int;
    n_burnin::Int              = min(1000, div(n_samples, 5)),
    initial_params::NamedTuple = _get_default_initparams_mcmc(pym)
) where {T} -&gt; PosteriorSamples{T}</code></pre><p>Generate <code>n_samples</code> posterior samples from a <code>PitmanYorMixture</code> using an augmented marginal Gibbs sampler.</p><p><strong>Arguments</strong></p><ul><li><code>rng</code>: Optional random seed used for random variate generation.</li><li><code>pym</code>: The <code>PitmanYorMixture</code> object for which posterior samples are generated.</li><li><code>n_samples</code>: The total number of samples (including burn-in).</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>n_burnin</code>: Number of burn-in samples.</li><li><code>initial_params</code>: Initial values used in the MCMC algorithm. Should be supplied as a <code>NamedTuple</code> with fields <code>:μ</code>, <code>:σ2</code> and <code>:cluster_alloc</code>, where <code>μ</code> and <code>σ2</code> are vector of the same dimension, and <code>cluster_alloc</code> is vector of length <code>length(x)</code> indicating the cluster membership of each observation.</li></ul><p><strong>Returns</strong></p><ul><li><code>ps</code>: A <a href="../../api/general_api/#BayesDensityCore.PosteriorSamples"><code>PosteriorSamples</code></a> object holding the posterior samples and the original model object.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using Random

julia&gt; x = (1.0 .- (1.0 .- LinRange(0.0, 1.0, 5000)) .^(1/3)).^(1/3);

julia&gt; pym = PitmanYorMixture(x);

julia&gt; ps = sample(Xoshiro(1), model, 5000);

julia&gt; ps = sample(Xoshiro(1), model, 5000; initial_params = (μ = [0.2, 0.8], σ2 = [1.0, 1.0], cluster_alloc = vcat(fill(1, 2500), fill(2, 2500))));</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/oskarhs/BayesDensity.jl/blob/60868ddfae2932b3f5aa7ed19c3e21e58d6522de/lib/BayesDensityPitmanYorMixture/src/mcmc.jl#L1-L36">source</a></section></details></article><h3 id="Variational-inference"><a class="docs-heading-anchor" href="#Variational-inference">Variational inference</a><a id="Variational-inference-1"></a><a class="docs-heading-anchor-permalink" href="#Variational-inference" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="BayesDensityPitmanYorMixture.PitmanYorMixtureVIPosterior"><a class="docstring-binding" href="#BayesDensityPitmanYorMixture.PitmanYorMixtureVIPosterior"><code>BayesDensityPitmanYorMixture.PitmanYorMixtureVIPosterior</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">PitmanYorMixtureVIPosterior{T&lt;:Real} &lt;: AbstractVIPosterior{T}</code></pre><p>Struct representing the variational posterior distribution of a <a href="#PitmanYorMixture"><code>PitmanYorMixture</code></a>.</p><p><strong>Fields</strong></p><ul><li><code>q_v</code>: Vector of distributions representing the optimal variational densities q*(vₖ), i.e. the density of the stick-breaking weights.</li><li><code>q_θ</code>: Vector of distributions representing the optimal variational densities q*(θₖ), i.e. the joint density of the mixture component means and variances.</li><li><code>pym</code>: The <code>PitmanYorMixture</code> to which the variational posterior was fit.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/oskarhs/BayesDensity.jl/blob/60868ddfae2932b3f5aa7ed19c3e21e58d6522de/lib/BayesDensityPitmanYorMixture/src/variational.jl#L1-L10">source</a></section></details></article><article><details class="docstring" open="true"><summary id="BayesDensityCore.varinf-Tuple{PitmanYorMixture}"><a class="docstring-binding" href="#BayesDensityCore.varinf-Tuple{PitmanYorMixture}"><code>BayesDensityCore.varinf</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">varinf(
    pym::PitmanYorMixture{T};
    truncation_level::Int      = 25,
    initial_params::NamedTuple = _get_default_initparams(pym, truncation_level),
    max_iter::Int              = 3000
    rtol::Real                 = 1e-6
) where {T} -&gt; PitmanYorMixtureVIPosterior{T}</code></pre><p>Find a variational approximation to the posterior distribution of a <a href="#PitmanYorMixture"><code>PitmanYorMixture</code></a> using mean-field variational inference based on a truncated stickbreaking-approach.</p><p><strong>Arguments</strong></p><ul><li><code>pym</code>: The <code>PitmanYorMixture</code> whose posterior we want to approximate.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>truncation level</code>: Positive integer specifying the truncation level of the variational approximation. Defaults to <code>25</code>.</li><li><code>initial_params</code>: Initial values of the VI parameters <code>a_v</code> <code>b_v</code>, <code>locations</code> and <code>inv_scale_facs</code>, <code>shapes</code> and <code>rates</code>, supplied as a NamedTuple. Must have dimensions matching the supplied truncation level.</li><li><code>max_iter</code>: Maximal number of VI iterations. Defaults to <code>3000</code>.</li><li><code>rtol</code>: Relative tolerance used to determine convergence. Defaults to <code>1e-6</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>vip</code>: A <a href="#BayesDensityPitmanYorMixture.PitmanYorMixtureVIPosterior"><code>PitmanYorMixtureVIPosterior</code></a> object representing the variational posterior.</li><li><code>info</code>: A <a href="../../api/general_api/#BayesDensityCore.VariationalOptimizationResult"><code>VariationalOptimizationResult</code></a> describing the result of the optimization.</li></ul><div class="admonition is-info" id="Note-1c882b4669472036"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-1c882b4669472036" title="Permalink"></a></header><div class="admonition-body"><p>To perform the optimization for a fixed number of iterations irrespective of the convergence criterion, one can set <code>rtol = 0.0</code>, and <code>max_iter</code> equal to the desired total iteration count. Note that setting <code>rtol</code> to a strictly negative value will issue a warning.</p></div></div><p><strong>Extended help</strong></p><p><strong>Convergence</strong></p><p>The criterion used to determine convergence is that the relative change in the ELBO falls below the given <code>rtol</code>.</p><p><strong>Truncation</strong></p><p>The truncation level determines the maximal number of components used in the variational approximation. Generally, setting the truncation level to a higher value leads to an approximating class with a greater representational capacity, at the cost of increased computation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/oskarhs/BayesDensity.jl/blob/60868ddfae2932b3f5aa7ed19c3e21e58d6522de/lib/BayesDensityPitmanYorMixture/src/variational.jl#L66-L101">source</a></section></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../HistSmoother/">« HistSmoother</a><a class="docs-footer-nextpage" href="../FiniteGaussianMixture/">FiniteGaussianMixture »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 6 February 2026 13:45">Friday 6 February 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
